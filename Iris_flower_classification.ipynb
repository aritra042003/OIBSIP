{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Important Libraries for This Project"
      ],
      "metadata": {
        "id": "rJtBJ3GXYVbb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZbm5MVEU8-b"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset from the CSV file\n",
        "iris_df = pd.read_csv('/iris.csv')"
      ],
      "metadata": {
        "id": "7KC8C-LpiiU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "OI-KD51DYueQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(iris_df.head())  # Display the first few rows of the dataframe\n",
        "print(iris_df.info())  # Display information about the dataframe\n",
        "print(iris_df.columns)"
      ],
      "metadata": {
        "id": "zfs4WCBri71z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Visualization**"
      ],
      "metadata": {
        "id": "sYKv4yL_YEEi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create scatter plots between pairs of features\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Scatter plot between sepal length and sepal width\n",
        "plt.subplot(1, 2, 1)\n",
        "# Scatter plot between sepal length and sepal width\n",
        "plt.subplot(1, 2, 1)\n",
        "for species in iris_df['Species'].unique():\n",
        "    plt.scatter(iris_df[iris_df['Species'] == species]['SepalLengthCm'],\n",
        "                iris_df[iris_df['Species'] == species]['SepalWidthCm'],\n",
        "                label=species)\n",
        "plt.xlabel('Sepal Length (cm)')\n",
        "plt.ylabel('Sepal Width (cm)')\n",
        "plt.title('Sepal Length vs Sepal Width')\n",
        "plt.legend()\n",
        "\n",
        "# Scatter plot between petal length and petal width\n",
        "plt.subplot(1, 2, 2)\n",
        "for species in iris_df['Species'].unique():\n",
        "    plt.scatter(iris_df[iris_df['Species'] == species]['PetalLengthCm'],\n",
        "                iris_df[iris_df['Species'] == species]['PetalWidthCm'],\n",
        "                label=species)\n",
        "plt.xlabel('Petal Length (cm)')\n",
        "plt.ylabel('Petal Width (cm)')\n",
        "plt.title('Petal Length vs Petal Width')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Zt62mMHHrUj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "O0T3OtG7YTHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into features (X) and target variable (y)\n",
        "X = iris_df.drop('Species', axis=1)  # Features\n",
        "y = iris_df['Species']  # Target variable\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Perform feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "47uaDv8ZjgXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train The Model"
      ],
      "metadata": {
        "id": "QCD419L-ZW-_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression()\n",
        "model.fit(X_train_scaled, y_train)\n"
      ],
      "metadata": {
        "id": "zWW2pZXKm9zA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation of The Model"
      ],
      "metadata": {
        "id": "QYRN7Ov5ZjpZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the testing set\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "PN7dz54vnY8J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}